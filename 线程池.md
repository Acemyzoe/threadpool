# 线程池

利用多线程来进行任务处理，采用"即时创建，即时销毁"的策略。

提交给线程的任务是执行时间较短，而且执行次数非常频繁，那么服务器就将处于一个不停的创建线程和销毁线程的状态。

> 完成一项任务需要的时间=创建线程时间T1+线程执行任务时间T2+销毁线程时间T3，如果T1+T3的时间远大于T2，通常就可以考虑采取线程池来提高服务器的性能。

线程池：**采用有限的线程个数处理无限的任务。**

## 线程池原理

在应用程序启动之后，就马上创建一定数量的线程，放入空闲的队列中。这些线程都是处于阻塞状态，这些线程只占一点内存，不占用CPU。当任务到来后，线程池将选择一个空闲的线程，将任务传入此线程中运行。

（**动态线程池**）当所有的线程都处在处理任务的时候，线程池将自动创建一定的数量的新线程，用于处理更多的任务。执行任务完成之后线程并不退出，而是继续在线程池中等待下一次任务。当大部分线程处于阻塞状态时，线程池将自动销毁一部分的线程，回收系统资源。

一般利用**条件变量**和**互斥锁**来实现线程池，模型可以参考生产消费者模型。

## 线程池组成

- 完成任务的一个或多个线程
- 要求执行线程的任务队列
- 用于调度管理的管理线程

## 数据结构

链表或者数组：用于存储线程池中的线程。 `vector`

队列：用于存储需要放入线程池中执行的任务。`queue`

互斥量：线程同步。`mutex`

条件变量：当有任务需要执行时，用于通知正在等待的线程从任务队列中取出任务执行。`condition_variable`

## 线程池大小

高并发、任务执行时间短的业务或计算密集型任务，线程池线程数设置为CPU核数**N+1**，减少线程上下文的切换。

并发不高、任务执行时间长的业务或IO密集型的任务，因为IO操作并不占用CPU，线程池线程数设置为**2*N**。
　　

# 基于标准库

**thread库**：线程

**mutex库**：互斥量

**condition_variable库**：条件量

**future库**：从线程中返回异步任务结果，一般需要依靠**全局变量**，从安全角度看不妥。

C++11提供了std::future类模板。future对象提供访问异步操作结果的机制，从异步任务中返回结果。

## 固定大小线程池

`ThreadPool.h`

构造时初始化线程数量，线程池可以提交变参函数或拉姆达表达式的匿名函数执行,不直接支持类成员函数, 支持类静态成员函数或全局函数,opertor()函数等，可以获取执行返回值。

```c++
#ifndef THREAD_POOL_H
#define THREAD_POOL_H

#include <vector>
#include <queue>
#include <memory>
#include <thread>             // std::thread 线程相关
#include <mutex>              // std::mutex, std::unique_lock 互斥量
#include <condition_variable> // 条件量，用于线程间通信，唤醒阻塞线程
#include <future>             // std::future 获取线程数据
#include <functional>         // std::function 函数对象
#include <stdexcept>          // std::runtime_error   标准异常

class ThreadPool // 线程池类
{
public:
    ThreadPool(size_t); // 构造函数，初始化线程池
    //一个enqueue模板函数 返回std::future<type>, type利用了运行时检测推断出类型
    //可以提交变参函数或拉姆达表达式的匿名函数执行,可以获取执行返回值
    template <class F, class... Args>                              // 模板函数，接受任意参数
    auto enqueue(F &&f, Args &&...args)                            // 将任务添加到任务队列中
        -> std::future<typename std::result_of<F(Args...)>::type>; // 返回任务执行结果
    ~ThreadPool();                                                 // 析构函数，终止线程池

private:
    std::vector<std::thread> workers;        // 工作线程
    std::queue<std::function<void()>> tasks; // 任务队列

    // synchronization
    std::mutex queue_mutex;            // 互斥量，用于线程间同步
    std::condition_variable condition; // 条件量，用于线程间同步
    bool stop;                         // 线程池是否终止
};

// the constructor just launches some amount of workers
inline ThreadPool::ThreadPool(size_t threads)
    : stop(false) // 初始化线程池
{
    for (size_t i = 0; i < threads; ++i)
        workers.emplace_back(
            [this]
            {
                for (;;)
                {
                    std::function<void()> task; // 任务函数对象
                    {
                        std::unique_lock<std::mutex> lock(this->queue_mutex); // 互斥量，用于线程间同步
                        this->condition.wait(lock,
                                             [this]
                                             { return this->stop || !this->tasks.empty(); }); // 等待条件量，等待任务队列不为空（condition是返回false才会wait）
                        if (this->stop && this->tasks.empty())                                // 如果线程池终止，且任务队列为空
                            return;
                        task = std::move(this->tasks.front()); // 取出任务队列中的第一个任务
                        this->tasks.pop();                     // 删除任务队列中的第一个任务
                    }
                    task(); // 执行任务
                }
            });
}

// add new work item to the pool
template <class F, class... Args>
auto ThreadPool::enqueue(F &&f, Args &&...args)               // 接受任意参数
    -> std::future<typename std::result_of<F(Args...)>::type> // 返回任务执行结果
{
    using return_type = typename std::result_of<F(Args...)>::type;

    auto task = std::make_shared<std::packaged_task<return_type()>>(
        std::bind(std::forward<F>(f), std::forward<Args>(args)...));

    std::future<return_type> res = task->get_future(); // 获取任务执行结果
    {                                                  // 加锁入队
        std::unique_lock<std::mutex> lock(queue_mutex);

        // don't allow enqueueing after stopping the pool
        if (stop)
            throw std::runtime_error("enqueue on stopped ThreadPool");

        tasks.emplace([task]()
                      { (*task)(); }); // 将任务添加到任务队列中
    }
    condition.notify_one(); // 通知工作线程
    return res;
}

// the destructor joins all threads
inline ThreadPool::~ThreadPool()
{
    {
        std::unique_lock<std::mutex> lock(queue_mutex);
        stop = true;
    }
    condition.notify_all();             // 唤醒所有线程
    for (std::thread &worker : workers) // 等待所有线程结束
        worker.join();
}

#endif
```

一个使用示例：

```c++
#include <iostream>
#include <vector>
#include <chrono>
#include "ThreadPool.h"

int main()
{

    ThreadPool pool(4);
    std::vector<std::future<int>> results;

    for (int i = 0; i < 5; ++i)
    {
        results.emplace_back(
            pool.enqueue([i]
                         {
                std::cout << std::this_thread::get_id() << std::endl;
                std::this_thread::sleep_for(std::chrono::seconds(2));
                return i; }));
    }

    for (auto &&result : results)
        std::cout << result.get() << std::endl;

    return 0;
}
// g++ example3.cpp -o example3 -pthread
```



# 基于Asio

asio官方给出了[基于boost::asio的线程池实现][Recipes (think-async.com)](http://think-async.com/Asio/Recipes))

## 用于执行任意任务的线程池

创建一个`io_service`：

```cpp
asio::io_service io_service;
```

`run()`如果它无事可做，一些工作会阻止其功能退出：

```cpp
asio::io_service::work work(io_service);
```

启动一些工作线程：

```cpp
boost::thread_group threads;
for (std::size_t i = 0; i < my_thread_count; ++i)
  threads.create_thread(boost::bind(&asio::io_service::run, &io_service));
```

将任务发布到 `io_service`以便它们可以由工作线程执行：	

```cpp
io_service.post(boost::bind(an_expensive_calculation, 42));
io_service.post(boost::bind(a_long_running_task, 123));
```

最后，在程序退出之前关闭`io_service`并等待所有线程退出：

```cpp
io_service.post(boost::bind(an_expensive_calculation, 42));
io_service.stop();
threads.join_all();
```

